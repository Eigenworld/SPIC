{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6172,
     "status": "ok",
     "timestamp": 1584584347068,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "0WxC9zbr5z9n",
    "outputId": "3b782185-3f77-4c41-8bce-2f0f68fc9168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.6/dist-packages (1.4.3)\n",
      "Requirement already satisfied: rdflib in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (4.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (0.22.2.post1)\n",
      "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (0.16.2)\n",
      "Requirement already satisfied: plyfile in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (0.7.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (1.18.1)\n",
      "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (0.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (1.4.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (2.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (0.25.3)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (2.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (2.21.0)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch_geometric) (0.47.0)\n",
      "Requirement already satisfied: isodate in /usr/local/lib/python3.6/dist-packages (from rdflib->torch_geometric) (0.6.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch_geometric) (2.4.6)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch_geometric) (0.14.1)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch_geometric) (2.4.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch_geometric) (3.2.0)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch_geometric) (7.0.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->torch_geometric) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch_geometric) (4.4.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch_geometric) (2018.9)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch_geometric) (2.8.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch_geometric) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch_geometric) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch_geometric) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch_geometric) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch_geometric) (2019.11.28)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch_geometric) (45.2.0)\n",
      "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch_geometric) (0.31.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch_geometric) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->torch_geometric) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11214,
     "status": "ok",
     "timestamp": 1584584355433,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "uFUELP8N5_7Q",
    "outputId": "268b03f3-07ca-4168-bea0-67621703d5bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0.html\n",
      "Collecting torch-scatter==latest+cu101\n",
      "  Using cached https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting torch-sparse==latest+cu101\n",
      "  Using cached https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.18.1)\n",
      "Installing collected packages: torch-scatter, torch-sparse\n",
      "  Found existing installation: torch-scatter 2.0.4\n",
      "    Uninstalling torch-scatter-2.0.4:\n",
      "      Successfully uninstalled torch-scatter-2.0.4\n",
      "  Found existing installation: torch-sparse 0.6.0\n",
      "    Uninstalling torch-sparse-0.6.0:\n",
      "      Successfully uninstalled torch-sparse-0.6.0\n",
      "Successfully installed torch-scatter-2.0.4 torch-sparse-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-scatter==latest+cu101 torch-sparse==latest+cu101 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.4.0.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 21642,
     "status": "ok",
     "timestamp": 1583464574267,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "Jmj4_2sowxPi",
    "outputId": "784cff6b-bf2a-4df5-c812-f145024f7e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-shF8UN6AEq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pysXaOqi8NBE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/drive/My Drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2RFLZ9U6AMi"
   },
   "outputs": [],
   "source": [
    "from my_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWwL_F4H_dwV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ljuQ8S_-ypX"
   },
   "outputs": [],
   "source": [
    "train_node_ratio = 44906. / 56944\n",
    "val_node_ratio = 6514. / 56944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3586,
     "status": "ok",
     "timestamp": 1584584360127,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "hTEnpMYx-I-P",
    "outputId": "fbdf41ad-0651-4c79-86ac-97aeaf6f1014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "运行很顺畅！\n"
     ]
    }
   ],
   "source": [
    "data = load_PPI_for_transductive_learning(train_node_ratio, val_node_ratio, 2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3544,
     "status": "ok",
     "timestamp": 1584584360127,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "OmNQCIQGN9zL",
    "outputId": "23e104b9-c9fe-4dba-e918-1eaea2422983"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[2, 65166], mask=[3144], x=[3144, 50], y=[3144, 121]),\n",
       " Data(edge_index=[2, 129676], mask=[4602], x=[4602, 50], y=[4602, 121]),\n",
       " Data(edge_index=[2, 56977], mask=[2599], x=[2599, 50], y=[2599, 121]),\n",
       " Data(edge_index=[2, 119031], mask=[4311], x=[4311, 50], y=[4311, 121]),\n",
       " Data(edge_index=[2, 117809], mask=[3903], x=[3903, 50], y=[3903, 121]),\n",
       " Data(edge_index=[2, 114765], mask=[4279], x=[4279, 50], y=[4279, 121]),\n",
       " Data(edge_index=[2, 157821], mask=[5299], x=[5299, 50], y=[5299, 121]),\n",
       " Data(edge_index=[2, 150300], mask=[5120], x=[5120, 50], y=[5120, 121]),\n",
       " Data(edge_index=[2, 168049], mask=[5465], x=[5465, 50], y=[5465, 121]),\n",
       " Data(edge_index=[2, 191680], mask=[6184], x=[6184, 50], y=[6184, 121]),\n",
       " Data(edge_index=[2, 205434], mask=[6514], x=[6514, 50], y=[6514, 121]),\n",
       " Data(edge_index=[2, 167500], mask=[5524], x=[5524, 50], y=[5524, 121])]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " list(data['train_loader'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RvteCeXG_fMm"
   },
   "outputs": [],
   "source": [
    "train_loader = list(data['train_loader'])\n",
    "train_loader = [train_loader[2]]\n",
    "val_loader = list(data['val_loader'])\n",
    "val_loader = [val_loader[2]]\n",
    "test_loader = list(data['test_loader'])\n",
    "test_loader = [test_loader[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2509,
     "status": "ok",
     "timestamp": 1584584360695,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "c-fihOQeRVri",
    "outputId": "681b4204-2cec-429e-a654-d6411ce82705"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Data(edge_index=[2, 56977], mask=[2599], x=[2599, 50], y=[2599, 121])]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6bMzUOhc6AOe"
   },
   "outputs": [],
   "source": [
    "class BCEWithLogitsWrapper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BCEWithLogitsWrapper, self).__init__()\n",
    "        self.loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        return self.loss(logits, labels.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MWLrJkQPpvW"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qccCA7P85ZVM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F_ThSyX0Qp15"
   },
   "outputs": [],
   "source": [
    "from utils import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dh_2Uizv7i_T"
   },
   "outputs": [],
   "source": [
    "num_features = 50\n",
    "num_classes = 121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "79jY5J9b6cSw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ovjIXqRWxYz"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GATConv(num_features, 256, heads=4)\n",
    "        self.lin1 = torch.nn.Linear(num_features, 4 * 256)\n",
    "        self.conv2 = GATConv(4 * 256, 256, heads=4)\n",
    "        self.lin2 = torch.nn.Linear(4* 256, 4 * 256)\n",
    "        self.conv3 = GATConv(\n",
    "            4 * 256, num_classes, heads=4, concat=False)\n",
    "        self.lin3 = torch.nn.Linear(4* 256, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        #x, edge_index = data.x, data.edge_index\n",
    "        #x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index) + self.lin1(x))\n",
    "        #x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv2(x, edge_index) + self.lin2(x))\n",
    "        x = self.conv3(x, edge_index) + self.lin3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "riBNWa3O25RW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsBGDp_p7aIA"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "#loss_op = torch.nn.BCEWithLogitsLoss()\n",
    "loss_op = BCEWithLogitsWrapper()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=5e-6)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1G_-vKx7aKA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 138132,
     "status": "ok",
     "timestamp": 1584539484930,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "fSzzAZ9V7aL-",
    "outputId": "272d1b8d-e76d-446e-c204-d876349122eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): GATConv(50, 256, heads=4)\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv2): GATConv(1024, 256, heads=4)\n",
      "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (conv3): GATConv(1024, 121, heads=4)\n",
      "  (lin3): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6463\n",
      "Net(\n",
      "  (conv1): GATConv(50, 256, heads=4)\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv2): GATConv(1024, 256, heads=4)\n",
      "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (conv3): GATConv(1024, 121, heads=4)\n",
      "  (lin3): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6493\n",
      "Net(\n",
      "  (conv1): GATConv(50, 256, heads=4)\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv2): GATConv(1024, 256, heads=4)\n",
      "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (conv3): GATConv(1024, 121, heads=4)\n",
      "  (lin3): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6485\n",
      "Net(\n",
      "  (conv1): GATConv(50, 256, heads=4)\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv2): GATConv(1024, 256, heads=4)\n",
      "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (conv3): GATConv(1024, 121, heads=4)\n",
      "  (lin3): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6590\n",
      "Net(\n",
      "  (conv1): GATConv(50, 256, heads=4)\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv2): GATConv(1024, 256, heads=4)\n",
      "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (conv3): GATConv(1024, 121, heads=4)\n",
      "  (lin3): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6578\n",
      "Net(\n",
      "  (conv1): GATConv(50, 256, heads=4)\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv2): GATConv(1024, 256, heads=4)\n",
      "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (conv3): GATConv(1024, 121, heads=4)\n",
      "  (lin3): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6576\n",
      "Net(\n",
      "  (conv1): GATConv(50, 256, heads=4)\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv2): GATConv(1024, 256, heads=4)\n",
      "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (conv3): GATConv(1024, 121, heads=4)\n",
      "  (lin3): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6585\n",
      "Net(\n",
      "  (conv1): GATConv(50, 256, heads=4)\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv2): GATConv(1024, 256, heads=4)\n",
      "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (conv3): GATConv(1024, 121, heads=4)\n",
      "  (lin3): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6574\n",
      "Net(\n",
      "  (conv1): GATConv(50, 256, heads=4)\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv2): GATConv(1024, 256, heads=4)\n",
      "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (conv3): GATConv(1024, 121, heads=4)\n",
      "  (lin3): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6583\n",
      "Net(\n",
      "  (conv1): GATConv(50, 256, heads=4)\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv2): GATConv(1024, 256, heads=4)\n",
      "  (lin2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "  (conv3): GATConv(1024, 121, heads=4)\n",
      "  (lin3): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6662\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gats = []\n",
    "for _ in range(10):\n",
    "  batch_size = 2\n",
    "  def train():\n",
    "      model.train()\n",
    "\n",
    "      total_loss = 0\n",
    "\n",
    "      for dat in train_loader:\n",
    "          num_graphs = batch_size\n",
    "          \n",
    "          #dat.batch = None\n",
    "          dat = dat.to(device)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outs = model(dat.x, dat.edge_index)\n",
    "          loss = loss_op(outs[dat.mask], dat.y[dat.mask])\n",
    "          temp = loss.item() * num_graphs\n",
    "          total_loss += temp\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "      return total_loss /2\n",
    "\n",
    "\n",
    "  def test(loader):\n",
    "      model.eval()\n",
    "\n",
    "      ys, preds = [], []\n",
    "      for dat in loader:\n",
    "          ys.append(dat.y[dat.mask])\n",
    "          with torch.no_grad():\n",
    "              out = model(dat.x.to(device), dat.edge_index.to(device))[dat.mask]\n",
    "          preds.append((out > 0).float().cpu())\n",
    "\n",
    "      y, pred = torch.cat(ys, dim=0).numpy(), torch.cat(preds, dim=0).numpy()\n",
    "      return f1_score(y, pred, average='micro') if pred.sum() > 0 else 0\n",
    "\n",
    "\n",
    "  early_stop = True\n",
    "  if early_stop:\n",
    "      stopper = EarlyStopping(patience=100)\n",
    "  dur = []\n",
    "\n",
    "  print(model)\n",
    "  for epoch in range(1, 101):\n",
    "      model.train()\n",
    "      if epoch >= 3:\n",
    "          t0 = time.time()\n",
    "      loss = train()\n",
    "      \n",
    "      if epoch >= 3:\n",
    "          dur.append(time.time() - t0)\n",
    "      \n",
    "      val_f1 = test(val_loader)\n",
    "      \n",
    "      if early_stop:\n",
    "          if stopper.step(val_f1, model):   \n",
    "              break\n",
    "            \n",
    "  if early_stop:\n",
    "      model.load_state_dict(torch.load('es_checkpoint.pt'))\n",
    "  test_f1 = test(test_loader)\n",
    "  gats.append(test_f1)\n",
    "  print(\"Test Accuracy {:.4f}\".format(test_f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1751,
     "status": "ok",
     "timestamp": 1584539614239,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "dJm2Pgxa7aW3",
    "outputId": "2eccaff4-f2cc-4cbb-e755-e0835a7a43e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.646, 0.649, 0.649, 0.659, 0.658, 0.658, 0.658, 0.657, 0.658, 0.666]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(gats,3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1222,
     "status": "ok",
     "timestamp": 1584539619054,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "y-OS8qdxPFL9",
    "outputId": "f6418267-fef7-4832-901a-7244bf620f3c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6558688047363785"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(gats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTHBrrh-PFb1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_e-DrHnW69OS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cm98sJZR9mpr"
   },
   "source": [
    "GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N8rLi1nmPFhn"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbLbNucgPFlC"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 4* 256, cached=True)\n",
    "       \n",
    "        self.conv2 = GCNConv(4* 256, 4 * 256, cached=True)\n",
    "        \n",
    "        self.conv3 = GCNConv(4 * 256, num_classes, cached=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "       \n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rg69Mdj-PFoE"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "loss_op = BCEWithLogitsWrapper()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.03)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 49082,
     "status": "ok",
     "timestamp": 1584540888927,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "6dW_GPGHPFrF",
    "outputId": "db0c523d-69d3-4862-ff11-fad66c9e78de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): GCNConv(50, 1024)\n",
      "  (conv2): GCNConv(1024, 1024)\n",
      "  (conv3): GCNConv(1024, 121)\n",
      ")\n",
      "Test Accuracy 0.6155\n",
      "Net(\n",
      "  (conv1): GCNConv(50, 1024)\n",
      "  (conv2): GCNConv(1024, 1024)\n",
      "  (conv3): GCNConv(1024, 121)\n",
      ")\n",
      "Test Accuracy 0.6106\n",
      "Net(\n",
      "  (conv1): GCNConv(50, 1024)\n",
      "  (conv2): GCNConv(1024, 1024)\n",
      "  (conv3): GCNConv(1024, 121)\n",
      ")\n",
      "Test Accuracy 0.6267\n",
      "Net(\n",
      "  (conv1): GCNConv(50, 1024)\n",
      "  (conv2): GCNConv(1024, 1024)\n",
      "  (conv3): GCNConv(1024, 121)\n",
      ")\n",
      "Test Accuracy 0.6299\n",
      "Net(\n",
      "  (conv1): GCNConv(50, 1024)\n",
      "  (conv2): GCNConv(1024, 1024)\n",
      "  (conv3): GCNConv(1024, 121)\n",
      ")\n",
      "Test Accuracy 0.6119\n",
      "Net(\n",
      "  (conv1): GCNConv(50, 1024)\n",
      "  (conv2): GCNConv(1024, 1024)\n",
      "  (conv3): GCNConv(1024, 121)\n",
      ")\n",
      "Test Accuracy 0.6171\n",
      "Net(\n",
      "  (conv1): GCNConv(50, 1024)\n",
      "  (conv2): GCNConv(1024, 1024)\n",
      "  (conv3): GCNConv(1024, 121)\n",
      ")\n",
      "Test Accuracy 0.6299\n",
      "Net(\n",
      "  (conv1): GCNConv(50, 1024)\n",
      "  (conv2): GCNConv(1024, 1024)\n",
      "  (conv3): GCNConv(1024, 121)\n",
      ")\n",
      "Test Accuracy 0.6199\n",
      "Net(\n",
      "  (conv1): GCNConv(50, 1024)\n",
      "  (conv2): GCNConv(1024, 1024)\n",
      "  (conv3): GCNConv(1024, 121)\n",
      ")\n",
      "Test Accuracy 0.6233\n",
      "Net(\n",
      "  (conv1): GCNConv(50, 1024)\n",
      "  (conv2): GCNConv(1024, 1024)\n",
      "  (conv3): GCNConv(1024, 121)\n",
      ")\n",
      "Test Accuracy 0.6271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gcns = []\n",
    "for _ in range(10):\n",
    "  batch_size = 2\n",
    "  def train():\n",
    "      model.train()\n",
    "\n",
    "      total_loss = 0\n",
    "\n",
    "      for dat in train_loader:\n",
    "         \n",
    "          num_graphs = batch_size\n",
    "          \n",
    "          #dat.batch = None\n",
    "          dat = dat.to(device)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outs = model(dat.x, dat.edge_index)\n",
    "          \n",
    "          loss = loss_op(outs[dat.mask], dat.y[dat.mask])\n",
    "          temp = loss.item() * num_graphs\n",
    "          total_loss += temp\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          \n",
    "      return total_loss /2\n",
    "\n",
    "\n",
    "  def test(loader):\n",
    "      model.eval()\n",
    "\n",
    "      ys, preds = [], []\n",
    "      for dat in loader:\n",
    "          ys.append(dat.y[dat.mask])\n",
    "          with torch.no_grad():\n",
    "              out = model(dat.x.to(device), dat.edge_index.to(device))[dat.mask]\n",
    "          preds.append((out > 0).float().cpu())\n",
    "\n",
    "      y, pred = torch.cat(ys, dim=0).numpy(), torch.cat(preds, dim=0).numpy()\n",
    "      return f1_score(y, pred, average='micro') if pred.sum() > 0 else 0\n",
    "\n",
    "\n",
    "  early_stop = True\n",
    "  if early_stop:\n",
    "      stopper = EarlyStopping(patience=100)\n",
    "  dur = []\n",
    "\n",
    "  print(model)\n",
    "  for epoch in range(1, 101):\n",
    "      model.train()\n",
    "      if epoch >= 3:\n",
    "          t0 = time.time()\n",
    "      loss = train()\n",
    "      \n",
    "      if epoch >= 3:\n",
    "          dur.append(time.time() - t0)\n",
    "      \n",
    "      val_f1 = test(val_loader)\n",
    "      \n",
    "      if early_stop:\n",
    "          if stopper.step(val_f1, model):   \n",
    "              break\n",
    "            \n",
    "  if early_stop:\n",
    "      model.load_state_dict(torch.load('es_checkpoint.pt'))\n",
    "  test_f1 = test(test_loader)\n",
    "  gcns.append(test_f1)\n",
    "  print(\"Test Accuracy {:.4f}\".format(test_f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 47658,
     "status": "ok",
     "timestamp": 1584540888928,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "to8rKkd59023",
    "outputId": "e049c6ea-f34e-45ca-c5aa-4f96d7ccc63a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.616, 0.611, 0.627, 0.63, 0.612, 0.617, 0.63, 0.62, 0.623, 0.627]"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(gcns,3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 46748,
     "status": "ok",
     "timestamp": 1584540888929,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "-1DFc9_w9C5R",
    "outputId": "0790147e-9ffd-4f02-ddad-707eb5a03c9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6211964104619412"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(gcns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "spT9F_jW9Drp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NLsKRS6DBNrQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6VDUR0FBNvb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LKOQoWDSBOKJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLlbPQ8_C9RP"
   },
   "source": [
    "## D_A_D_General/  DAD_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rcMnveFZBOBE"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import add_remaining_self_loops\n",
    "from torch_scatter import scatter_add\n",
    "\n",
    "\n",
    "class DADG_Conv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, K=1, cached=False, bias=True,\n",
    "                 improve=False, **kwargs):\n",
    "        super(DADG_Conv, self).__init__(aggr='add', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.improve = improve\n",
    "        self.cached = cached\n",
    "\n",
    "        self.lin = Linear(in_channels, out_channels, bias=bias)\n",
    "    \n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        #gain = nn.init.calculate_gain('relu')\n",
    "        \n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.lin.weight, gain=gain)\n",
    "        nn.init.zeros_(self.lin.bias)\n",
    "        self.cached_result = None\n",
    "        self.cached_num_edges = None\n",
    "        \n",
    "    '''def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        self.cached_result = None\n",
    "        self.cached_num_edges = None'''\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        \"\"\"\"\"\"\n",
    "        if self.cached and self.cached_result is not None:\n",
    "            if edge_index.size(1) != self.cached_num_edges:\n",
    "                raise RuntimeError(\n",
    "                    'Cached {} number of edges, but found {}. Please '\n",
    "                    'disable the caching behavior of this layer by removing '\n",
    "                    'the `cached=True` argument in its constructor.'.format(\n",
    "                        self.cached_num_edges, edge_index.size(1)))\n",
    "\n",
    "        #if not self.cached:\n",
    "            #x = self.lin(x)\n",
    "\n",
    "        if not self.cached or self.cached_result is None:\n",
    "            self.cached_num_edges = edge_index.size(1)\n",
    "            edge_index, norm = self.My_norms(edge_index, x.size(0), edge_weight, self.improve\n",
    "                                            , dtype=x.dtype)\n",
    "            for k in range(self.K):\n",
    "                #x = F.relu(self.propagate(edge_index, x=x, norm=norm))\n",
    "                x = self.propagate(edge_index, x=x, norm=norm)\n",
    "           \n",
    "            #self.cached_result = x\n",
    "\n",
    "        #if self.cached:\n",
    "            #x = self.lin(self.cached_result)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def My_norms(self, edge_index, num_nodes, edge_weight=None, improved=False,\n",
    "             dtype=None):\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,\n",
    "                                     device=edge_index.device)\n",
    "\n",
    "        fill_value = 1 if not improved else 2\n",
    "        edge_index, edge_weight = add_remaining_self_loops(\n",
    "            edge_index, edge_weight, fill_value, num_nodes)\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        #deg_inv_sqrt = deg.pow(-1)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "\n",
    "        #return edge_index, deg_inv_sqrt[col] * edge_weight \n",
    "        return edge_index, deg_inv_sqrt[col] * edge_weight*deg_inv_sqrt[row]\n",
    "    \n",
    "    def message(self, x_j, norm):\n",
    "        \n",
    "        x_j = self.lin(x_j)\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, K={})'.format(self.__class__.__name__,\n",
    "                                         self.in_channels, self.out_channels,\n",
    "                                         self.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hbAO4v48GzNE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YscPRU7vBN_O"
   },
   "outputs": [],
   "source": [
    "h_dim = 256*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "POXTdrg5BN9d"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(num_features, h_dim)\n",
    "        \n",
    "        self.conv1 = DADG_Conv(\n",
    "            h_dim, h_dim, K=2, cached=True, improve=True)\n",
    "        \n",
    "        self.lin2 = torch.nn.Linear(h_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.lin1(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xv7yEm9yAe5b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17704,
     "status": "error",
     "timestamp": 1584584295641,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "Xh230IgaBNzE",
    "outputId": "633a173b-96c7-4275-b950-9de5c394daa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): DADG_Conv(1024, 1024, K=5)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-2277d0f69daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m           \u001b[0mdur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m       \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-2277d0f69daf>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m     41\u001b[0m           \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m               \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m           \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "loss_op = BCEWithLogitsWrapper()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.03)#0.009\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.03, weight_decay=5e-6)\n",
    "\n",
    "\n",
    "dads = []\n",
    "for _ in range(10):\n",
    "  batch_size = 2\n",
    "  def train():\n",
    "      model.train()\n",
    "\n",
    "      total_loss = 0\n",
    "\n",
    "      for dat in train_loader:\n",
    "          \n",
    "          num_graphs = batch_size\n",
    "          \n",
    "          #dat.batch = None\n",
    "          dat = dat.to(device)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outs = model(dat.x, dat.edge_index)\n",
    "          \n",
    "          loss = loss_op(outs[dat.mask], dat.y[dat.mask])\n",
    "          temp = loss.item() * num_graphs\n",
    "          total_loss += temp\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          \n",
    "      return total_loss /2\n",
    "\n",
    "\n",
    "  def test(loader):\n",
    "      model.eval()\n",
    "\n",
    "      ys, preds = [], []\n",
    "      for dat in loader:\n",
    "          ys.append(dat.y[dat.mask])\n",
    "          with torch.no_grad():\n",
    "              out = model(dat.x.to(device), dat.edge_index.to(device))[dat.mask]\n",
    "          preds.append((out > 0).float().cpu())\n",
    "\n",
    "      y, pred = torch.cat(ys, dim=0).numpy(), torch.cat(preds, dim=0).numpy()\n",
    "      return f1_score(y, pred, average='micro') if pred.sum() > 0 else 0\n",
    "\n",
    "\n",
    "  early_stop = True\n",
    "  if early_stop:\n",
    "      stopper = EarlyStopping(patience=100)\n",
    "  dur = []\n",
    "\n",
    "  print(model)\n",
    "  for epoch in range(1, 101):\n",
    "      model.train()\n",
    "      if epoch >= 3:\n",
    "          t0 = time.time()\n",
    "      loss = train()\n",
    "      \n",
    "      if epoch >= 3:\n",
    "          dur.append(time.time() - t0)\n",
    "      \n",
    "      val_f1 = test(val_loader)\n",
    "      \n",
    "      if early_stop:\n",
    "          if stopper.step(val_f1, model):   \n",
    "              break\n",
    "            \n",
    "  if early_stop:\n",
    "      model.load_state_dict(torch.load('es_checkpoint.pt'))\n",
    "  test_f1 = test(test_loader)\n",
    "  dads.append(test_f1)\n",
    "  print(\"Test Accuracy {:.4f}\".format(test_f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAOwumd9NKZq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2163,
     "status": "ok",
     "timestamp": 1584583830728,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "4Pj_bhwaAwFE",
    "outputId": "75e185af-23b2-4a87-adb7-aebdbd664f46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.536, 0.537, 0.542, 0.543, 0.543, 0.543, 0.543, 0.543, 0.544, 0.544]"
      ]
     },
     "execution_count": 56,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(dads,3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2410,
     "status": "ok",
     "timestamp": 1584583831209,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "B8mr0FwiA2TI",
    "outputId": "9f8ccd2b-d825-4540-fc25-7f0776e46aee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5420386204047024"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2311,
     "status": "ok",
     "timestamp": 1584583874059,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "WF6Rx-eSA2pt",
    "outputId": "09124212-dd35-47f6-822b-5afb93a7052a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.541"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.537, 0.532, 0.531, 0.538, 0.538, 0.539, 0.54, 0.543, 0.543, 0.569]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyK3EYavHe0G"
   },
   "source": [
    "# D_A_D(SGC)/DAD_relu1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIIYNlamHUo1"
   },
   "outputs": [],
   "source": [
    "class P_GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, K=1, cached=True, bias=True,\n",
    "                 improve=False, **kwargs):\n",
    "        super(P_GCNConv, self).__init__(aggr='add', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.K = K\n",
    "        self.improve = improve\n",
    "        self.cached = cached\n",
    "\n",
    "        #self.lin = Linear(in_channels, out_channels, bias=bias)\n",
    "\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    '''def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_uniform_(self.lin.weight, gain=gain)\n",
    "        nn.init.zeros_(self.lin.bias)\n",
    "        self.cached_result = None\n",
    "        self.cached_num_edges = None'''\n",
    "\n",
    "    '''def reset_parameters(self):\n",
    "        uniform(self.in_channels, self.weight)\n",
    "        uniform(self.in_channels, self.bias)'''\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        #self.lin.reset_parameters()\n",
    "        self.cached_result = None\n",
    "        self.cached_num_edges = None\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight=None):\n",
    "        \"\"\"\"\"\"\n",
    "        if self.cached and self.cached_result is not None:\n",
    "            if edge_index.size(1) != self.cached_num_edges:\n",
    "                raise RuntimeError(\n",
    "                    'Cached {} number of edges, but found {}. Please '\n",
    "                    'disable the caching behavior of this layer by removing '\n",
    "                    'the `cached=True` argument in its constructor.'.format(\n",
    "                        self.cached_num_edges, edge_index.size(1)))\n",
    "\n",
    "        \n",
    "\n",
    "        if not self.cached or self.cached_result is None:\n",
    "            self.cached_num_edges = edge_index.size(1)\n",
    "            edge_index, norm = self.My_norms(edge_index, x.size(0), edge_weight, self.improve\n",
    "                                            , dtype=x.dtype)\n",
    "            x = F.relu(self.propagate(edge_index, x=x, norm=norm))\n",
    "\n",
    "            for k in range(self.K-1):\n",
    "                x = self.propagate(edge_index, x=x, norm=norm)\n",
    "                \n",
    "            #self.cached_result = x\n",
    "\n",
    "        '''if self.cached:\n",
    "            x = self.lin(self.cached_result)'''\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def My_norms(self, edge_index, num_nodes, edge_weight=None, improved=False,\n",
    "             dtype=None):\n",
    "        if edge_weight is None:\n",
    "            edge_weight = torch.ones((edge_index.size(1), ), dtype=dtype,\n",
    "                                     device=edge_index.device)\n",
    "\n",
    "        fill_value = 1 if not improved else 2\n",
    "        edge_index, edge_weight = add_remaining_self_loops(\n",
    "            edge_index, edge_weight, fill_value, num_nodes)\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = scatter_add(edge_weight, row, dim=0, dim_size=num_nodes)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n",
    "\n",
    "        return edge_index, deg_inv_sqrt[col] * edge_weight*deg_inv_sqrt[row] \n",
    "        \n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, K={})'.format(self.__class__.__name__,\n",
    "                                         self.in_channels, self.out_channels,\n",
    "                                         self.K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DeDkcdlHVDy"
   },
   "outputs": [],
   "source": [
    "h_dim = 256*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTRESKbtA3ML"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(num_features, h_dim)\n",
    "        \n",
    "        self.conv1 = P_GCNConv(\n",
    "            h_dim, h_dim, K=2, cached=True, improve=True)\n",
    "        \n",
    "        self.lin2 = torch.nn.Linear(h_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.lin1(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gciXeoWMHt75"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60590,
     "status": "ok",
     "timestamp": 1584581578936,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "NQevfsDrHuhb",
    "outputId": "50e957cb-02b2-4c60-c7f2-b9115ca0978e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GCNConv(1024, 1024, K=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6481\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GCNConv(1024, 1024, K=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6483\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GCNConv(1024, 1024, K=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6526\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GCNConv(1024, 1024, K=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6394\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GCNConv(1024, 1024, K=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6384\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GCNConv(1024, 1024, K=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6473\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GCNConv(1024, 1024, K=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6444\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GCNConv(1024, 1024, K=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6479\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GCNConv(1024, 1024, K=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6468\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GCNConv(1024, 1024, K=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.6366\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "loss_op = BCEWithLogitsWrapper()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.03)#0.009\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.05, weight_decay=5e-6)\n",
    "\n",
    "sgcs = []\n",
    "for _ in range(10):\n",
    "  batch_size = 2\n",
    "  def train():\n",
    "      model.train()\n",
    "\n",
    "      total_loss = 0\n",
    "\n",
    "      for dat in train_loader:\n",
    "          \n",
    "          num_graphs = batch_size\n",
    "          \n",
    "          #dat.batch = None\n",
    "          dat = dat.to(device)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outs = model(dat.x, dat.edge_index)\n",
    "          \n",
    "          loss = loss_op(outs[dat.mask], dat.y[dat.mask])\n",
    "          temp = loss.item() * num_graphs\n",
    "          total_loss += temp\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          \n",
    "      return total_loss /2\n",
    "\n",
    "\n",
    "  def test(loader):\n",
    "      model.eval()\n",
    "\n",
    "      ys, preds = [], []\n",
    "      for dat in loader:\n",
    "          ys.append(dat.y[dat.mask])\n",
    "          with torch.no_grad():\n",
    "              out = model(dat.x.to(device), dat.edge_index.to(device))[dat.mask]\n",
    "          preds.append((out > 0).float().cpu())\n",
    "\n",
    "      y, pred = torch.cat(ys, dim=0).numpy(), torch.cat(preds, dim=0).numpy()\n",
    "      return f1_score(y, pred, average='micro') if pred.sum() > 0 else 0\n",
    "\n",
    "\n",
    "  early_stop = True\n",
    "  if early_stop:\n",
    "      stopper = EarlyStopping(patience=100)\n",
    "  dur = []\n",
    "\n",
    "  print(model)\n",
    "  for epoch in range(1, 101):\n",
    "      model.train()\n",
    "      if epoch >= 3:\n",
    "          t0 = time.time()\n",
    "      loss = train()\n",
    "      \n",
    "      if epoch >= 3:\n",
    "          dur.append(time.time() - t0)\n",
    "      \n",
    "      val_f1 = test(val_loader)\n",
    "      \n",
    "      if early_stop:\n",
    "          if stopper.step(val_f1, model):   \n",
    "              break\n",
    "            \n",
    "  if early_stop:\n",
    "      model.load_state_dict(torch.load('es_checkpoint.pt'))\n",
    "  test_f1 = test(test_loader)\n",
    "  sgcs.append(test_f1)\n",
    "  print(\"Test Accuracy {:.4f}\".format(test_f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3016,
     "status": "ok",
     "timestamp": 1584581594174,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "9daFCAucJV-D",
    "outputId": "b119dbc2-b808-4972-d5ca-669036f43b7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.648, 0.648, 0.653, 0.639, 0.638, 0.647, 0.644, 0.648, 0.647, 0.637]"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(sgcs,3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1502,
     "status": "ok",
     "timestamp": 1584581594175,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "aF3ZJLRIJbI2",
    "outputId": "bfcb2a9b-208e-461e-edfd-33d71268811d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.644992122991823"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sgcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KibgxYrLHubb"
   },
   "outputs": [],
   "source": [
    "lr=0.005, weight_decay=5e-6 0.456\n",
    "\n",
    "lr=0.05, weight_decay=5e-6 0.48, 0.46\n",
    "lr=0.02, weight_decay=5e-6 0.47, 0.46\n",
    "lr=0.01, weight_decay=5e-6  0.47, 0.46\n",
    "\n",
    "lr=0.05, weight_decay=5e-4  0.45 0.47\n",
    "lr=0.05, weight_decay=5e-2 0.46, 0.45 \n",
    "\n",
    "lr=0.5, weight_decay=5e-6 0.4575 0.4533\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XuLVlOWFI7fU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lVAo807HuUU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2PWDloG2fEgM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fe2z7WdycEXK"
   },
   "source": [
    "# P_GAT_General！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TO4oHKQqNKju"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "class P_GATConv(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, k=2, negative_slope=0.2, dropout=0.6, bias=True, **kwargs):\n",
    "        super(P_GATConv, self).__init__(aggr='add', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "\n",
    "        self.lin = Linear(in_channels, out_channels, bias=bias)\n",
    "        self.att = Parameter(torch.Tensor(1, 2 * out_channels))\n",
    "      \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.lin.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.att, gain=gain)\n",
    "        if self.bias:\n",
    "            nn.init.zeros_(self.lin.bias)\n",
    "\n",
    "    ''' def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        #self.lin2.reset_parameters()\n",
    "        glorot(self.att)'''\n",
    "    \n",
    "    def My_norms(self, x, edge_index, num_nodes):\n",
    "        edge_index_j = edge_index[0]\n",
    "        edge_index_i = edge_index[1]\n",
    "        x_j = x[edge_index_j]\n",
    "        x_i = x[edge_index_i]\n",
    "        \n",
    "        alpha0 = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1)\n",
    "        alpha1 = (torch.cat([x_j, x_i], dim=-1) * self.att).sum(dim=-1)\n",
    "        alpha = (alpha0 + alpha1)/2.0\n",
    "        \n",
    "        #alpha = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1)\n",
    "\n",
    "        alpha = F.leaky_relu(alpha, self.negative_slope)\n",
    "\n",
    "        \n",
    "        alpha = softmax(alpha, edge_index_i, num_nodes)\n",
    "        \n",
    "        # Sample attention coefficients stochastically.\n",
    "        #alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        \n",
    "        return alpha\n",
    "    \n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        \"\"\"\"\"\"\n",
    "        if size is None and torch.is_tensor(x):\n",
    "            edge_index, _ = remove_self_loops(edge_index)\n",
    "            edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        #x = self.lin(x)\n",
    "        \n",
    "        norm = self.My_norms(x, edge_index, x.size(0))\n",
    "        # x 不放在relu里！！！\n",
    "        for _ in range(self.k):\n",
    "\n",
    "            x = F.relu(self.propagate(edge_index, size=size, x=x, norm=norm)) +x\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        x_j = self.lin(x_j)\n",
    "        return norm.view(-1, 1) * x_j\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, heads={})'.format(self.__class__.__name__,\n",
    "                                             self.in_channels,\n",
    "                                             self.out_channels, self.k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjd_kWWMoiqk"
   },
   "source": [
    "# P-GAT/P-GAT-relu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VDeiJqRof8q"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn.inits import glorot, zeros\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
    "\n",
    "class P_GAT(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, k=2, negative_slope=0.2, dropout=0.6, bias=True, improved=False,**kwargs):\n",
    "        super(P_GAT, self).__init__(aggr='add', **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.k = k\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "        self.improved = improved\n",
    "\n",
    "        self.lin = Linear(in_channels, out_channels, bias=bias)\n",
    "        self.att = Parameter(torch.Tensor(1, 2 * out_channels))\n",
    "      \n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        gain = nn.init.calculate_gain('relu')\n",
    "        nn.init.xavier_normal_(self.lin.weight, gain=gain)\n",
    "        nn.init.xavier_normal_(self.att, gain=gain)\n",
    "        if self.bias:\n",
    "            nn.init.zeros_(self.lin.bias)\n",
    "\n",
    "    ''' def reset_parameters(self):\n",
    "        self.lin.reset_parameters()\n",
    "        #self.lin2.reset_parameters()\n",
    "        glorot(self.att)'''\n",
    "    \n",
    "    def My_norms(self, x, edge_index, num_nodes, improved=False):\n",
    "        edge_index_j = edge_index[0]\n",
    "        edge_index_i = edge_index[1]\n",
    "        x_j = x[edge_index_j]\n",
    "        x_i = x[edge_index_i]\n",
    "        \n",
    "        alpha0 = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1)\n",
    "        alpha1 = (torch.cat([x_j, x_i], dim=-1) * self.att).sum(dim=-1)\n",
    "        alpha = (alpha0 + alpha1)/2.0\n",
    "\n",
    "        if improved:\n",
    "            self_weight = edge_index_i== edge_index_j\n",
    "            alpha[self_weight] += 1.0\n",
    "        \n",
    "        #alpha = (torch.cat([x_i, x_j], dim=-1) * self.att).sum(dim=-1)\n",
    "\n",
    "        alpha = F.leaky_relu(alpha, self.negative_slope)\n",
    "\n",
    "        \n",
    "        alpha = softmax(alpha, edge_index_i, num_nodes)\n",
    "        \n",
    "        # Sample attention coefficients stochastically.\n",
    "        #alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        \n",
    "        return alpha\n",
    "    \n",
    "    def forward(self, x, edge_index, size=None):\n",
    "        \"\"\"\"\"\"\n",
    "        if size is None and torch.is_tensor(x):\n",
    "            edge_index, _ = remove_self_loops(edge_index)\n",
    "            edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        \n",
    "        x = self.lin(x)\n",
    "        \n",
    "        norm = self.My_norms(x, edge_index, x.size(0))\n",
    "            \n",
    "\n",
    "        \n",
    "        x = F.relu(self.propagate(edge_index, size=size, x=x, norm=norm)) +x\n",
    "\n",
    "        for _ in range(self.k-1):\n",
    "\n",
    "            x = self.propagate(edge_index, size=size, x=x, norm=norm) + x\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, heads={})'.format(self.__class__.__name__,\n",
    "                                             self.in_channels,\n",
    "                                             self.out_channels, self.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hF06odUycCNo"
   },
   "outputs": [],
   "source": [
    "#h_dim =  2 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8qayiJL_Fva"
   },
   "outputs": [],
   "source": [
    "h_dim =  4 * 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-pQFGpmcC4A"
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.lin1 = torch.nn.Linear(num_features, h_dim)\n",
    "        \n",
    "        self.conv1 = P_GAT(\n",
    "             h_dim, h_dim, k=2)\n",
    "        \n",
    "        self.lin2 = torch.nn.Linear(h_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.lin1(x)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "loss_op = BCEWithLogitsWrapper()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)#0.002\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.005, weight_decay=5e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1GFEdblEcDQ7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 141808,
     "status": "ok",
     "timestamp": 1584588658833,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "DmCAR2fBcDOo",
    "outputId": "638ee4bd-bc1c-4a8d-ea2b-f09b5ac76afc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GAT(1024, 1024, heads=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.4932\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GAT(1024, 1024, heads=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.4978\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GAT(1024, 1024, heads=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.5186\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GAT(1024, 1024, heads=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.5155\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GAT(1024, 1024, heads=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.5159\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GAT(1024, 1024, heads=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.5150\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GAT(1024, 1024, heads=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.5257\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GAT(1024, 1024, heads=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.5327\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GAT(1024, 1024, heads=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.5374\n",
      "Net(\n",
      "  (lin1): Linear(in_features=50, out_features=1024, bias=True)\n",
      "  (conv1): P_GAT(1024, 1024, heads=2)\n",
      "  (lin2): Linear(in_features=1024, out_features=121, bias=True)\n",
      ")\n",
      "Test Accuracy 0.5244\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gat_g_s = []\n",
    "for _ in range(10):\n",
    "  batch_size = 2\n",
    "  def train():\n",
    "      model.train()\n",
    "\n",
    "      total_loss = 0\n",
    "\n",
    "      for dat in train_loader:\n",
    "          \n",
    "          num_graphs = batch_size\n",
    "          \n",
    "          #dat.batch = None\n",
    "          dat = dat.to(device)\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          outs = model(dat.x, dat.edge_index)\n",
    "          \n",
    "          loss = loss_op(outs[dat.mask], dat.y[dat.mask])\n",
    "          temp = loss.item() * num_graphs\n",
    "          total_loss += temp\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          \n",
    "      return total_loss /2\n",
    "\n",
    "\n",
    "  def test(loader):\n",
    "      model.eval()\n",
    "\n",
    "      ys, preds = [], []\n",
    "      for dat in loader:\n",
    "          ys.append(dat.y[dat.mask])\n",
    "          with torch.no_grad():\n",
    "              out = model(dat.x.to(device), dat.edge_index.to(device))[dat.mask]\n",
    "          preds.append((out > 0).float().cpu())\n",
    "\n",
    "      y, pred = torch.cat(ys, dim=0).numpy(), torch.cat(preds, dim=0).numpy()\n",
    "      return f1_score(y, pred, average='micro') if pred.sum() > 0 else 0\n",
    "\n",
    "\n",
    "  early_stop = True\n",
    "  if early_stop:\n",
    "      stopper = EarlyStopping(patience=100)\n",
    "  dur = []\n",
    "\n",
    "  print(model)\n",
    "  for epoch in range(1, 101):\n",
    "      model.train()\n",
    "      if epoch >= 3:\n",
    "          t0 = time.time()\n",
    "      loss = train()\n",
    "      \n",
    "      if epoch >= 3:\n",
    "          dur.append(time.time() - t0)\n",
    "      \n",
    "      val_f1 = test(val_loader)\n",
    "      \n",
    "      if early_stop:\n",
    "          if stopper.step(val_f1, model):   \n",
    "              break\n",
    "            \n",
    "  if early_stop:\n",
    "      model.load_state_dict(torch.load('es_checkpoint.pt'))\n",
    "  test_f1 = test(test_loader)\n",
    "  gat_g_s.append(test_f1)\n",
    "  print(\"Test Accuracy {:.4f}\".format(test_f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 140341,
     "status": "ok",
     "timestamp": 1584588658834,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "xaS0l_ILcDMY",
    "outputId": "0f3f5eb2-9a23-43a7-d622-014a0094b247"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.493, 0.498, 0.519, 0.516, 0.516, 0.515, 0.526, 0.533, 0.537, 0.524]"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(gat_g_s,3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 139684,
     "status": "ok",
     "timestamp": 1584588658835,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "jEeYA3wwFfiA",
    "outputId": "de3df269-1b17-4fd6-f722-ed7c8cf0ad92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5176159163261744"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(gat_g_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 135557,
     "status": "ok",
     "timestamp": 1584588658835,
     "user": {
      "displayName": "Alexy Robert",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ggz_PITpCVZkOGCc-PYV93u9s6v6n1BoAux_QBT=s64",
      "userId": "05809751795814209528"
     },
     "user_tz": -480
    },
    "id": "5PVgXsS-Ff6R",
    "outputId": "f5a1b577-4ffe-4a48-88f7-65acb226bb06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tjAVKALKwf_s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "caDKEepGDYMo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0tH1Ty7yDYYK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8imhQKypCTDS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tlhRBGVQCTP2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nw1yrnNKCTaM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dgulUL5nCTlK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNmN1MwfloqA3xFghsehfQ+",
   "collapsed_sections": [],
   "mount_file_id": "1s-1ERKRsiLjvh_OyfeFVBrlSwrUwTh3S",
   "name": "ppi_war!.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
